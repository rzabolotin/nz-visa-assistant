{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c741a360-a8dc-4925-89b6-7dc9b90980a3",
   "metadata": {},
   "source": [
    "# Hybrid search\n",
    "Try to implement techinques from 6 week of the course\n",
    "- Hybrid search\n",
    "- Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e22b20-eab0-46c9-8a16-4900e08ed94e",
   "metadata": {},
   "source": [
    "## Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a2f4e5-053b-4423-b775-d3b3dcf0fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd54bc-b05a-4d8a-b577-59820c51294b",
   "metadata": {},
   "source": [
    "## Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d84cb1-f50e-4790-9a2c-b729ff72e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "def ndcg(relevance_total):\n",
    "    def dcg(relevance):\n",
    "        return sum((2**rel - 1) / math.log2(i + 2) for i, rel in enumerate(relevance))\n",
    "    \n",
    "    def idcg(relevance):\n",
    "        return dcg(sorted(relevance, reverse=True))\n",
    "    \n",
    "    scores = []\n",
    "    for relevance in relevance_total:\n",
    "        if sum(relevance) == 0:\n",
    "            scores.append(0.0)\n",
    "        else:\n",
    "            scores.append(dcg(relevance) / idcg(relevance))\n",
    "    \n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        results = search_function(q['question'])\n",
    "        relevance = [d['url'] == q['url'] for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "        'ndsg': ndcg(relevance_total)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9e739-a568-4480-9ee6-f18b3acbff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(raw_doc, chunk_size=1000, overlap=100):\n",
    "    def chunk_content(content, chunk_size=1000, overlap=100):\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        while start < len(content):\n",
    "            end = start + chunk_size\n",
    "            chunk = content[start:end]\n",
    "            chunks.append(chunk)\n",
    "            start = end - overlap\n",
    "        return chunks\n",
    "\n",
    "    chunked_data = []\n",
    "    for k, v in raw_doc.items():\n",
    "        content_chunks = chunk_content(v['main_content'], chunk_size, overlap)\n",
    "        for i, chunk in enumerate(content_chunks):\n",
    "            chunked_data.append({\n",
    "                'url': k,\n",
    "                'header': v['header'],\n",
    "                'main_content': chunk,\n",
    "                'chunk_index': i\n",
    "            })\n",
    "    \n",
    "    return chunked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b07c3-9728-48b3-a744-142762b89867",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012e4ab-a1f2-417f-a049-18cd47fcdc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ground-truth.json', 'r') as f_in:\n",
    "    ground_truth = json.load(f_in)\n",
    "\n",
    "with open('../data/site_content.json', 'r') as f_in:\n",
    "    raw_doc = json.load(f_in)\n",
    "\n",
    "\n",
    "data = [{'url': k, 'header':v['header'], 'main_content':v['main_content']} for k,v in raw_doc.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a6e7e-90c1-4f85-8a8f-74728270f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk = chunk_data(raw_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df4cd5-60f4-407b-84b1-b878a06c1ee6",
   "metadata": {},
   "source": [
    "### Elastic search indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1bacb5-493e-4863-831f-0fcdccb94f88",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd712af-e935-4285-90dc-702958a0c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/.local/share/virtualenvs/llm-zoomcamp-project2-jok7aU-Z/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'esearchvector_chunks'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "model_name = \"all-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"url\": {\"type\": \"text\"},\n",
    "            \"header\": {\"type\": \"text\"},\n",
    "            \"main_content\": {\"type\": \"text\"},\n",
    "            \"main_content_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": model.get_sentence_embedding_dimension(),\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name_vector = \"esearchvector_chunks\"\n",
    "\n",
    "es_client.indices.delete(index=index_name_vector, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name_vector, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de70446-a241-4601-8cca-930957ca0baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2834/2834 [05:55<00:00,  7.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(data_chunk):\n",
    "    doc['header_vector'] = model.encode(doc['header'])\n",
    "    doc['main_content_vector'] = model.encode(doc['main_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79053c-1777-4625-8cae-26189f7c5ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2834/2834 [00:32<00:00, 86.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(data_chunk):\n",
    "    es_client.index(index=index_name_vector, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0978d71-9e94-406f-b6b0-d08d57adf3b6",
   "metadata": {},
   "source": [
    "## Test previous search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396f83d-00c0-4ce3-b563-d5b04bc306f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_combined_10(query):\n",
    "    vector = model.encode(query)\n",
    "    search_query = {\n",
    "        \"_source\": [\"url\", \"header\", \"main_content\", \"header_vector\", \"main_content_vector\"],\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query,\n",
    "                            \"fields\": [\"header\", \"main_content\"],\n",
    "                            \"type\": \"best_fields\",\n",
    "                            \"tie_breaker\": 0.3\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                            \"query\": {\"match_all\": {}},\n",
    "                            \"script\": {\n",
    "                                \"source\": \"cosineSimilarity(params.query_vector, 'main_content_vector') + 1.0\",\n",
    "                                \"params\": {\"query_vector\": vector}\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 10\n",
    "    }\n",
    "    \n",
    "    es_results = es_client.search(\n",
    "        index=index_name_vector,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = [hit['_source'] for hit in es_results['hits']['hits']]\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c784f-12f0-410e-b02b-d20bd6bb8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, elastic_search_combined_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86126399-bfe2-498d-8c8b-d934ab6973b0",
   "metadata": {},
   "source": [
    "## New hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae29d5-6f1a-4045-b8e2-63c9ea7f3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid(query):\n",
    "    vector = model.encode(query)\n",
    "    knn_query = {\n",
    "        \"field\": \"main_content_vector\",\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5\n",
    "    }\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"header\", \"main_content\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn_query,\n",
    "        \"query\": keyword_query,\n",
    "        \"size\": 10,\n",
    "        \"_source\": [\"header\", \"main_content\", \"url\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name_vector,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f37e9-80cf-49d0-9c47-a16199700d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, elastic_search_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123dc5fd-8cc4-462d-99cd-d90e8406df5f",
   "metadata": {},
   "source": [
    "## Add reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca5f91-1b1d-473d-a191-808831708b9d",
   "metadata": {},
   "source": [
    "Update docker version\n",
    "\n",
    "```bash\n",
    "\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -m 4GB \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.9.0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3aa032-74d3-4f10-9982-b2fa7b426aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rrf(rank, k=60):\n",
    "    \"\"\" Our own implementation of the relevance score \"\"\"\n",
    "    return 1 / (k + rank)\n",
    "\n",
    "def elastic_search_hybrid_rrf(query, k=60):\n",
    "    vector = model.encode(query)\n",
    "    knn_query = {\n",
    "        \"field\": \"main_content_vector\",\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5\n",
    "    }\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"main_content\", \"main_content\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    knn_results = es_client.search(\n",
    "        index=index_name_vector, \n",
    "        body={\n",
    "            \"knn\": knn_query, \n",
    "            \"size\": 20\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    keyword_results = es_client.search(\n",
    "        index=index_name_vector, \n",
    "        body={\n",
    "            \"query\": keyword_query, \n",
    "            \"size\": 20\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    rrf_scores = {}\n",
    "    # Calculate RRF using vector search results\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Adding keyword search result scores\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        if doc_id in rrf_scores:\n",
    "            rrf_scores[doc_id] += compute_rrf(rank + 1, k)\n",
    "        else:\n",
    "            rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Sort RRF scores in descending order\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-K documents by the score\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:10]:\n",
    "        doc = es_client.get(index=index_name_vector, id=doc_id)\n",
    "        final_results.append(doc['_source'])\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c49b7-23bf-475b-a91f-0b7775cd8aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 415/415 [00:45<00:00,  9.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7132530120481928,\n",
       " 'mrr': 0.6751185695161596,\n",
       " 'ndsg': 0.5400964249775241}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, elastic_search_hybrid_rrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed082c-2dde-4754-a4a5-75a9c793de87",
   "metadata": {},
   "source": [
    "### Final results\n",
    "Results of hybrid search and reranking methods compared to the best previous Elasticsearch configuration. The metrics used for evaluation include Hit Rate, MRR (Mean Reciprocal Rank), and NDCG (Normalized Discounted Cumulative Gain).\n",
    "\n",
    "| Method | Hit Rate | MRR | NDCG |\n",
    "|--------|----------|-----|------|\n",
    "| Elasticsearch (combined search, size 10) | 0.6578 | 0.7077 | 0.4997 |\n",
    "| Hybrid search | 0.6771 | 0.6801 | 0.5076 |\n",
    "| Reranking | 0.7157 | 0.6870 | 0.5471 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eaaccd-217f-4914-876f-2517821512ee",
   "metadata": {},
   "source": [
    "## Using langchain_elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7adc68-9655-4f35-ba84-0fb95362fb16",
   "metadata": {},
   "source": [
    "For the sake of gaining more experience with LangChain, let's use langchain_elasticsearch to retrieve data, and check that it works the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ff421-1629-45a5-932e-554cabafb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_elasticsearch import ElasticsearchRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1bed23-50ae-4455-b2b2-cff5e539738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_url = 'http://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f1d21e-c95b-4603-909a-0d70a8a76782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-MiniLM-L12-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66de159-ae47-46b2-ad62-53e437800fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=f\"sentence-transformers/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d61ca-775a-4b2b-9fa3-bd568aef4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid_rrf_langchain(query, k=60):\n",
    "    def knn_query(vector):\n",
    "        return {\n",
    "            \"knn\": {\n",
    "                \"field\": \"main_content_vector\",\n",
    "                \"query_vector\": vector,\n",
    "                \"k\": 10,\n",
    "                \"num_candidates\": 10000,\n",
    "                \"boost\": 0.5\n",
    "            }, \n",
    "            \"size\": 20\n",
    "        }\n",
    "    def keyword_query(query):\n",
    "        return {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query,\n",
    "                            \"fields\": [\"main_content\", \"main_content\"],\n",
    "                            \"type\": \"best_fields\",\n",
    "                            \"boost\": 0.5,\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }, \n",
    "            \"size\": 20\n",
    "        }\n",
    "\n",
    "    def id_query(doc_id):\n",
    "        return {\n",
    "            \"query\": {\n",
    "                \"ids\": {\n",
    "                    \"values\": [doc_id]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    vector = embeddings.embed_query(query)\n",
    "\n",
    "    knn_retriever = ElasticsearchRetriever.from_es_params(\n",
    "        index_name=index_name_vector,\n",
    "        body_func=knn_query,\n",
    "        content_field='main_content',\n",
    "        url=es_url,\n",
    "    )\n",
    "\n",
    "    knn_results = knn_retriever.invoke(vector)\n",
    "\n",
    "    keyword_retriever = ElasticsearchRetriever.from_es_params(\n",
    "        index_name=index_name_vector,\n",
    "        body_func=keyword_query,\n",
    "        content_field='main_content',\n",
    "        url=es_url,\n",
    "    )\n",
    "\n",
    "    id_retriever = ElasticsearchRetriever.from_es_params(\n",
    "        index_name=index_name_vector,\n",
    "        body_func=id_query,\n",
    "        content_field='main_content',\n",
    "        url=es_url,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    keyword_results = keyword_retriever.invoke(query)\n",
    "    \n",
    "    \n",
    "    rrf_scores = {}\n",
    "    # Calculate RRF using vector search results\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit.metadata['_id']\n",
    "        rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Adding keyword search result scores\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit.metadata['_id']\n",
    "        if doc_id in rrf_scores:\n",
    "            rrf_scores[doc_id] += compute_rrf(rank + 1, k)\n",
    "        else:\n",
    "            rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Sort RRF scores in descending order\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-K documents by the score\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:10]:\n",
    "        results = id_retriever.invoke(doc_id)\n",
    "        if results:\n",
    "            final_results.append(results[0].metadata['_source'])\n",
    "        else:\n",
    "            print(f\"Warning: Document with id {doc_id} not found\")\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca0998-3bf0-4946-be35-9a5b338bb460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 415/415 [01:01<00:00,  6.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7132530120481928,\n",
       " 'mrr': 0.6751185695161596,\n",
       " 'ndsg': 0.5400964249775241}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, elastic_search_hybrid_rrf_langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b4a54-28d8-45a6-9d7d-ee2ec6e20e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
